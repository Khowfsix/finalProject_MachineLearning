{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b39f75",
   "metadata": {},
   "source": [
    "# Nhận diện chữ số viết tay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc3f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from __future__ import print_function\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from skimage import exposure\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4dda0d",
   "metadata": {},
   "source": [
    "# Bước 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66f1ab9",
   "metadata": {},
   "source": [
    "Cấu trúc bộ dữ liệu ban đầu: Bộ dữ liệu ban đầu bao gồm 1.797 chữ số biểu thị số 0-9. Những hình ảnh này là thang độ xám, hình ảnh 8 x 8 với các chữ số xuất hiện dưới dạng màu trắng trên nền đen. Các chữ số này cũng đã được xử lý trước, căn chỉnh và tập trung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3912ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the MNIST digits dataset\n",
    "mnist = datasets.load_digits()\n",
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96daada8",
   "metadata": {},
   "source": [
    "# Bước 2\n",
    "Tách dữ liệu: tách dữ liệu làm 3 phần: phần training, phần validation và phần test\n",
    "\n",
    "Lấy 75% dữ liệu làm phần training, 25% testing, rồi lấy 10% của phần training làm validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56160504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data points: 1212\n",
      "validation data points: 135\n",
      "testing data points: 450\n"
     ]
    }
   ],
   "source": [
    "# take the MNIST data and construct the training and testing split, using 75% of the\n",
    "# data for training and 25% for testing\n",
    "\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(mnist.data), \n",
    "                                                                  mnist.target, \n",
    "                                                                  test_size=0.25, \n",
    "                                                                  random_state=42)\n",
    "\n",
    "# now, let's take 10% of the training data and use that for validation\n",
    "(trainData, valData, trainLabels, valLabels) = train_test_split(trainData, \n",
    "                                                                trainLabels, \n",
    "                                                                test_size=0.1, \n",
    "                                                                random_state=84)\n",
    "\n",
    "# show the sizes of each data split\n",
    "print(\"training data points: {}\".format(len(trainLabels)))\n",
    "print(\"validation data points: {}\".format(len(valLabels)))\n",
    "print(\"testing data points: {}\".format(len(testLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2996d85",
   "metadata": {},
   "source": [
    "# Bước 3\n",
    "Trích xuất các tính năng: Thay vì trích xuất các tính năng để thể hiện và mô tả từng chữ số (như HOG, khoảnh khắc zernike, v.v.), thay vào đó chúng ta sẽ chỉ sử dụng cường độ pixel thô, thang độ xám của hình ảnh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744fe199",
   "metadata": {},
   "source": [
    "# Bước 4\n",
    "Train model phân loại: Trình phân loại K-NN sẽ được training về cường độ pixel thô của hình ảnh trong training data set. Sau đó, xác định giá trị tốt nhất của K bằng cách sử dụng bộ xác thực.\n",
    "\n",
    "Ở đây ta thử nghiệm hết cả values của k của KNN rồi sau đó ta chọn k có độ chính xác cao nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e04aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the values of k for our k-Nearest Neighbor classifier along with the\n",
    "# list of accuracies for each value of k\n",
    "kVals = range(1, 30, 2)\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa290e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=99.26%\n",
      "k=3, accuracy=99.26%\n",
      "k=5, accuracy=99.26%\n",
      "k=7, accuracy=99.26%\n",
      "k=9, accuracy=99.26%\n",
      "k=11, accuracy=99.26%\n",
      "k=13, accuracy=99.26%\n",
      "k=15, accuracy=99.26%\n",
      "k=17, accuracy=98.52%\n",
      "k=19, accuracy=98.52%\n",
      "k=21, accuracy=97.78%\n",
      "k=23, accuracy=97.04%\n",
      "k=25, accuracy=97.78%\n",
      "k=27, accuracy=97.04%\n",
      "k=29, accuracy=97.04%\n"
     ]
    }
   ],
   "source": [
    "for k in range(1, 30, 2):\n",
    "    # train the k-Nearest Neighbor classifier with the current value of 'k'\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(trainData, trainLabels)\n",
    "\n",
    "    # evaluate the model and update the accuracies list\n",
    "    score = model.score(valData, valLabels)\n",
    "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    accuracies.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25e49c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 achieved highest accuracy of 99.26% on validation data\n"
     ]
    }
   ],
   "source": [
    "# find the value of k that has the largest accuracy\n",
    "i = int(np.argmax(accuracies))\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i], accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff993d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "model.fit(trainData, trainLabels)\n",
    "predictions = model.predict(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4985d17f",
   "metadata": {},
   "source": [
    "# Bước 5\n",
    "Đánh giá trình phân loại của chúng tôi: Một khi chúng tôi đã tìm thấy giá trị tốt nhất của K, sau đó chúng tôi có thể đánh giá trình phân loại K-NN của chúng tôi trên bộ thử nghiệm của chúng tôi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "381eb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.97        37\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.98      0.98      0.98        46\n",
      "           4       0.98      0.98      0.98        55\n",
      "           5       0.98      1.00      0.99        59\n",
      "           6       1.00      1.00      1.00        45\n",
      "           7       1.00      0.98      0.99        41\n",
      "           8       0.97      0.95      0.96        38\n",
      "           9       0.96      0.94      0.95        48\n",
      "\n",
      "    accuracy                           0.98       450\n",
      "   macro avg       0.98      0.98      0.98       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0994d",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bd80bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think that digit is: 4\n",
      "I think that digit is: 8\n",
      "I think that digit is: 5\n",
      "I think that digit is: 3\n",
      "I think that digit is: 4\n"
     ]
    }
   ],
   "source": [
    "# loop over a few random digits\n",
    "for i in list(map(int, np.random.randint(0, high=len(testLabels), size=(5,)))):\n",
    "    # grab the image and classify it\n",
    "    image = testData[i]\n",
    "    prediction = model.predict(image.reshape(1, -1))[0]\n",
    "\n",
    "    # convert the image for a 64-dim array to an 8 x 8 image compatible with OpenCV,\n",
    "    # then resize it to 32 x 32 pixels so we can see it better\n",
    "    image = image.reshape((8, 8)).astype(\"uint8\")\n",
    "    image = exposure.rescale_intensity(image, out_range=(0, 255))\n",
    "    image = imutils.resize(image, width=32, inter=cv2.INTER_CUBIC)\n",
    "\n",
    "    # show the prediction\n",
    "    print(\"I think that digit is: {}\".format(prediction))\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16d194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d406c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebffdaee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
